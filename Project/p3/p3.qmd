---
title: "QMBE 3740 & CDS 1130 Final Project - 2020 Overwatch League Analysis"
output: html
runtime: shiny
format:
  html:
    code-fold: true
---

```{r setup, include=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(tidyverse)
library(ggplot2)
library(gridExtra)


knitr::opts_chunk$set(warning = FALSE)

tank = "#ff7eb6" # IBM Magenta 40
damage = "#4589ff" # IBM Blue 50
support = "#3ddbd9" # IBM Teal 30
```

## Introduction to Overwatch (2020)

Overwatch is a team-based shooter game with many heroes that come with their own abilities. In 2020, Overwatch League's gameplay involved teams of six engaging in 6v6 combat across various maps and objectives.

The game categorizes characters into three roles:

-   Tanks: These characters are the front line of every team. Tanks make space, absorb incoming damage, and set up plays for their teammates.
-   Damage: These characters are the follow up to the front line. They are either launching rockets from up behind cover or are deep behind enemy lines taking out their support.
-   Support: These characters usually take a back seat when it comes to eliminating the enemy team, by healing their team they ensure that their front-liners can take whatever comes at them, without getting taken out.

## Overwatch League: 2020 Season Analysis

The analysis focuses on the 2020 Overwatch League season, played on Overwatch's original format with six-player teams. This season is notable for its strategic and player dynamics, providing insight into player performances and tactics before Overwatch transitioned to a 5v5 format in its sequel, Overwatch 2.

The shift to 5v5 in Overwatch 2, particularly impacting the role and balance of Tank characters, offers an interesting contrast to the 2020 season data.

### Player Representation

The map below represents player nationality of which most players are from South Korea. We can see that most players are either from East Asian countries or Western Countries.

```{python player nationality map}
import pandas as pd
import geopandas as gpd
import plotly.express as px

file_path = 'overwatch_league_player_nationalities_updated.csv'
players_data = pd.read_csv(file_path)

if (players_data['Representation'] % 1 == 0).all():
    players_data['Representation'] = players_data['Representation'].astype(int)
else:
    players_data['Representation'] = players_data['Representation'].astype(float)

world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))
world_data = world.merge(players_data, left_on='name', right_on='Country / Region', how='left')

fig = px.choropleth(world_data,
                    geojson=world_data.geometry,
                    locations=world_data.index,
                    color="Representation",
                    color_continuous_scale="Viridis",
                    labels={'Representation':'Number of Players'})
fig.update_geos(fitbounds="locations")
```

```{r analysis setup, include=FALSE}
Mode <- function(x) {
    ux <- unique(x)
    if (length(ux) == 1) {
        return(ux)
    }
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)]
}

file_path <- "phs_2020_1_no_all_heroes.csv"
data <- read_csv(file_path)

hero_roles <- c(
    "D.Va" = "Tank", "Doomfist" = "Tank", "Junker Queen" = "Tank", "Mauga" = "Tank",
    "Orisa" = "Tank", "Ramattra" = "Tank", "Reinhardt" = "Tank", "Roadhog" = "Tank",
    "Sigma" = "Tank", "Winston" = "Tank", "Wrecking Ball" = "Tank", "Zarya" = "Tank",
    "Ashe" = "Damage", "Bastion" = "Damage", "McCree" = "Damage", "Echo" = "Damage",
    "Genji" = "Damage", "Hanzo" = "Damage", "Junkrat" = "Damage", "Mei" = "Damage",
    "Pharah" = "Damage", "Reaper" = "Damage", "Sojourn" = "Damage",
    "Soldier: 76" = "Damage", "Sombra" = "Damage", "Symmetra" = "Damage",
    "Torbjörn" = "Damage", "Tracer" = "Damage", "Widowmaker" = "Damage",
    "Ana" = "Support", "Baptiste" = "Support", "Brigitte" = "Support",
    "Illari" = "Support", "Kiriko" = "Support", "Lifeweaver" = "Support",
    "Lúcio" = "Support", "Mercy" = "Support", "Moira" = "Support", "Zenyatta" = "Support"
)
data <- data %>%
    mutate(role = hero_roles[hero_name])
eliminations_data <- filter(data, stat_name == "Eliminations")

average_eliminations <- eliminations_data %>%
    group_by(player_name, esports_match_id) %>%
    summarise(avg_elim = mean(stat_amount), .groups = "drop") %>%
    group_by(player_name) %>%
    summarise(average_eliminations = mean(avg_elim), .groups = "drop")
player_roles <- eliminations_data %>%
    group_by(player_name) %>%
    summarise(common_role = Mode(role), .groups = "drop")
player_impact <- merge(average_eliminations, player_roles, by = "player_name")
```

## Machine Learning

```{python ml, eval = FALSE}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
import numpy as np

data = pd.read_csv("merged_esports_data_updated.csv")
data = data.fillna(data.median(numeric_only=True))
data = pd.get_dummies(data, columns=["map_type", "map_name", "player_name", "team_name", "hero_name"])
data = data.drop(columns=["team_one_name", "team_two_name", "match_id"])
X = data.drop("match_winner", axis=1)
y = data["match_winner"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

lr_model = LogisticRegression().fit(X_train, y_train)
rf_model = RandomForestClassifier(n_estimators=50, random_state=42).fit(X_train, y_train)
gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)

predictions_lr = lr_model.predict(X_test)
predictions_rf = rf_model.predict(X_test)
predictions_gb = gb_model.predict(X_test)

results = pd.DataFrame({
    "y_test": y_test,
    "predictions_lr": predictions_lr,
    "predictions_rf": predictions_rf,
    "predictions_gb": predictions_gb
})
results.to_csv("model_results.csv", index=False)

feature_importances = pd.DataFrame({
    "feature": X.columns,
    "importance_rf": rf_model.feature_importances_,
    "importance_gb": gb_model.feature_importances_
})
feature_importances.to_csv("feature_importances.csv", index=False)
```

To better understand which features are most relevant to a team winning a game, we are going to train and test machine learning models to be able to predict which team is going to win based on the dataset's features.

From analyzing the feature importance, accuracy, sensitivity, and specificity of each model, we can see that the Random Forest model does the best job at correctly predicting which team is going to win.

```{r ml2, output = FALSE}
library(ggplot2)
library(dplyr)
library(caret)
library(reshape2)

results <- read.csv("model_results.csv")
feature_importances <- read.csv("feature_importances.csv")

top_features_rf <- feature_importances %>%
                   arrange(desc(importance_rf)) %>%
                   head(10)

top_features_gb <- feature_importances %>%
                   arrange(desc(importance_gb)) %>%
                   head(10)

cm_lr <- confusionMatrix(as.factor(results$predictions_lr), as.factor(results$y_test))
metrics_lr <- data.frame(Model = "Logistic Regression", Accuracy = cm_lr$overall['Accuracy'], Sensitivity = cm_lr$byClass['Sensitivity'], Specificity = cm_lr$byClass['Specificity'])

cm_rf <- confusionMatrix(as.factor(results$predictions_rf), as.factor(results$y_test))
metrics_rf <- data.frame(Model = "Random Forest", Accuracy = cm_rf$overall['Accuracy'], Sensitivity = cm_rf$byClass['Sensitivity'], Specificity = cm_rf$byClass['Specificity'])

cm_gb <- confusionMatrix(as.factor(results$predictions_gb), as.factor(results$y_test))
metrics_gb <- data.frame(Model = "Gradient Boosting", Accuracy = cm_gb$overall['Accuracy'], Sensitivity = cm_gb$byClass['Sensitivity'], Specificity = cm_gb$byClass['Specificity'])

combined_metrics <- rbind(metrics_lr, metrics_rf, metrics_gb)
melted_metrics <- melt(combined_metrics, id.vars = "Model")

ggplot(melted_metrics, aes(x = variable, y = value, fill = variable)) +
    geom_bar(stat = "identity", position = position_dodge()) +
    facet_wrap(~Model) +
    scale_fill_manual(values = c("Accuracy" = tank, "Sensitivity" = damage, "Specificity" = support)) +
    labs(x = "Metric", y = "Value", title = "Model Performance Comparison") +
    theme_minimal()
```

```{r ml3, echo = FALSE}
ggplot(melted_metrics, aes(x = variable, y = value, fill = variable)) +
    geom_bar(stat = "identity", position = position_dodge()) +
    facet_wrap(~Model) +
    scale_fill_manual(values = c("Accuracy" = tank, "Sensitivity" = damage, "Specificity" = support)) +
    labs(x = "Metric", y = "Value", title = "Model Performance Comparison") +
    theme_minimal()
```

A Random Forest Model is a "forest" of decision trees which take different features of the dataset, draws a line between win and lose, then categorizes any data we give it until it is correct most of the time.

For example, the decision trees could determine that more than 90 seconds of average alive time, more than 40 seconds of objective time, and more than 10 eliminations a game mean that someone is more likely to win. Continuing this example, a hero that has 100 seconds of average alive time, 41 seconds of objective time, and 9 eliminations, the Random Forest would say this is most likely to be a win, as average alive time and objective time outweigh eliminations.

```{r feature importance graph}
ggplot(top_features_rf, aes(x = reorder(feature, importance_rf), y = importance_rf)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    labs(title = "Top 10 Feature Importances - Random Forest")
```

The Random Forest Model uses in-game statistics to predict the winning team, whereas the Gradient Boosting model tends to favor a specific team in its selections; which is unhelpful in the long term when rosters change. Logistic Regression demonstrated an inability to accurately identify true negatives, which was also seen in the Gradient Boosting model. Therefore, considering the criteria of accuracy, realistic true positive identification, and effective true negative prediction, the Random Forest model significantly outperforms the other trained models.

```{r gb feature importance}
ggplot(top_features_gb, aes(x= reorder(feature, importance_gb), y = importance_gb)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    labs(title = "Top 10 Feature Importances - Gradient Boosting")
```

## Analyzing features based on the Random Forest's Feature Importance

### Average Time Alive

```{r average time alive box plot, output = FALSE}
time_alive_data <- filter(data, stat_name == "Average Time Alive")
avg_time_alive_by_hero <- time_alive_data %>%
    group_by(hero_name, role) %>%
    summarise(average_time_alive = mean(stat_amount, na.rm = TRUE)) %>%
    ungroup() %>%
    arrange(desc(average_time_alive))

ordered_heroes <- rev(avg_time_alive_by_hero$hero_name)
time_alive_data$hero_name <- factor(time_alive_data$hero_name, levels = ordered_heroes)

ggplot(time_alive_data, aes(x = hero_name, y = stat_amount, fill = role)) +
    geom_boxplot() +
    coord_flip() +
    labs(title = "Boxplot of Average Time Alive by Hero", x = "Hero", y = "Average Time Alive") +
    theme_minimal() +
    scale_fill_manual(values = c("Tank" = tank, "Damage" = damage, "Support" = support)) +
    theme(legend.position = "bottom")
```

```{r average tiem alive box plot2, echo = FALSE}
ggplot(time_alive_data, aes(x = hero_name, y = stat_amount, fill = role)) +
    geom_boxplot() +
    coord_flip() +
    labs(title = "Boxplot of Average Time Alive by Hero", x = "Hero", y = "Average Time Alive") +
    theme_minimal() +
    scale_fill_manual(values = c("Tank" = tank, "Damage" = damage, "Support" = support)) +
    theme(legend.position = "bottom")
```

Looking at this box plot we can see that Sombra has the highest Average Time Alive of any hero. This is most likely because she can use her translocator, which is a device she leaves on the floor somewhere and can instantly teleport back to at any time. Symmetra is the lowest on the list and this is most likely due to the fact that Symmetra is picked for a couple of seconds at the beginning of many rounds as her placable teleporter allows teams to quickly reposition right out of the gates.

### Average Objective Time

```{r objective time graphs, output = FALSE}
objective_time_data <- filter(data, stat_name == "Objective Time")
objective_time_by_hero <- objective_time_data %>%
    group_by(hero_name, role) %>%
    summarise(average_objective_time = mean(stat_amount, na.rm = TRUE)) %>%
    ungroup() %>%
    arrange(desc(average_objective_time))

ordered_heroes_objective <- rev(objective_time_by_hero$hero_name)
objective_time_data$hero_name <- factor(objective_time_data$hero_name, levels = ordered_heroes_objective)

ggplot(objective_time_data, aes(x = hero_name, y = stat_amount, fill = role)) +
    geom_boxplot() +
    coord_flip() +
    labs(title = "Boxplot of Objective Time by Hero", x = "Hero", y = "Objective Time") +
    theme_minimal() +
    scale_fill_manual(values = c("Tank" = tank, "Damage" = damage, "Support" = support))
```

```{r objective time graph2, echo = FALSE}
ggplot(objective_time_data, aes(x = hero_name, y = stat_amount, fill = role)) +
    geom_boxplot() +
    coord_flip() +
    labs(title = "Boxplot of Objective Time by Hero", x = "Hero", y = "Objective Time") +
    theme_minimal() +
    scale_fill_manual(values = c("Tank" = tank, "Damage" = damage, "Support" = support))
```

In this Average Objective Time plot we can see that Orisa, Reinhardt, and D.Va have the highest average objective time this season. This lines up with the Tank's role to create space for their team which includes taking and holding objective spaces. Heroes like Widowmaker who rely on off-angle positioning to be effective, are more likely to be near but not on the objective.

### Average Healing Done

```{r healing done plot, include = FALSE}
healing_done_data <- filter(data, stat_name == "Healing Done")
average_healing_by_hero <- healing_done_data %>%
    group_by(hero_name, role) %>%
    summarise(average_healing_done = mean(stat_amount, na.rm = TRUE)) %>%
    ungroup() %>%
    arrange(desc(average_healing_done))
ordered_heroes_healing <- rev(average_healing_by_hero$hero_name)
healing_done_data$hero_name <- factor(healing_done_data$hero_name, levels = ordered_heroes_healing)

ggplot(healing_done_data, aes(x = hero_name, y = stat_amount, fill = role)) +
    geom_boxplot() +
    coord_flip() +
    labs(title = "Boxplot of Healing Done by Hero", x = "Hero", y = "Healing Done") +
    theme_minimal() +
    scale_fill_manual(values = c("Tank" = tank, "Damage" = damage, "Support" = support))
```

```{r healing done plot2, echo = FALSE}
ggplot(healing_done_data, aes(x = hero_name, y = stat_amount, fill = role)) +
    geom_boxplot() +
    coord_flip() +
    labs(title = "Boxplot of Healing Done by Hero", x = "Hero", y = "Healing Done") +
    theme_minimal() +
    scale_fill_manual(values = c("Tank" = tank, "Damage" = damage, "Support" = support))
```

In this healing chart we can see that it is almost exclusively supports. This is because with the exception of Soldier: 76, supports are the only heroes that can heal their teammates. Moira being at the top of this list does not surprise me as she was one of the strongest picks during this season since she was able to deal damage and heal very effectively.

### Average Eliminations

```{r elimination graph, output = FALSE}
average_eliminations_by_hero <- eliminations_data %>%
    group_by(hero_name, role) %>%
    summarise(average_eliminations = mean(stat_amount, na.rm = TRUE)) %>%
    ungroup() %>%
    arrange(desc(average_eliminations))
ordered_heroes_eliminations <- rev(average_eliminations_by_hero$hero_name)
eliminations_data$hero_name <- factor(eliminations_data$hero_name, levels = ordered_heroes_eliminations)

ggplot(eliminations_data, aes(x = hero_name, y = stat_amount, fill = role)) +
    geom_boxplot() +
    coord_flip() +
    labs(title = "Boxplot of Eliminations by Hero", x = "Hero", y = "Number of Eliminations") +
    theme_minimal() +
    scale_fill_manual(values = c("Tank" = tank, "Damage" = damage, "Support" = support))
```

```{r elimination graph2, echo = FALSE}
ggplot(eliminations_data, aes(x = hero_name, y = stat_amount, fill = role)) +
    geom_boxplot() +
    coord_flip() +
    labs(title = "Boxplot of Eliminations by Hero", x = "Hero", y = "Number of Eliminations") +
    theme_minimal() +
    scale_fill_manual(values = c("Tank" = tank, "Damage" = damage, "Support" = support))
```

In ths graph, we can see that Damage and Tank heros generally trend towards the higher end of the graph while Supports who are mostly focused on healing and keeping their team alive have less focus spent on getting eliminations. Moira stands out as a support in the number 3 spot which can be explained by her kit which requires Moira to deal damage to regenerate her healing capibilities.

## Comparing our features next to each other

```{python}
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

owl2020_data = pd.read_csv('owl2020data.csv')
hero_roles = {
    "D.Va": "Tank", "Reinhardt": "Tank", "Winston": "Tank", "Roadhog": "Tank", "Zarya": "Tank", 
    "Orisa": "Tank", "Sigma": "Tank", "Wrecking Ball": "Tank", "Doomfist": "Damage", 
    "Genji": "Damage", "McCree": "Damage", "Pharah": "Damage", "Reaper": "Damage", 
    "Soldier: 76": "Damage", "Sombra": "Damage", "Tracer": "Damage", "Bastion": "Damage", 
    "Hanzo": "Damage", "Junkrat": "Damage", "Mei": "Damage", "Torbjörn": "Damage", 
    "Widowmaker": "Damage", "D.Va": "Tank", "Orisa": "Tank", "Reinhardt": "Tank", 
    "Roadhog": "Tank", "Winston": "Tank", "Wrecking Ball": "Tank", "Zarya": "Tank", 
    "Ana": "Support", "Baptiste": "Support", "Brigitte": "Support", "Lúcio": "Support", 
    "Mercy": "Support", "Moira": "Support", "Zenyatta": "Support"
}
owl2020_data['role'] = owl2020_data['hero_name'].map(hero_roles)
custom_palette = {
    "Tank": "#ff7eb6",
    "Damage": "#4589ff",
    "Support": "#3ddbd9"
}

plt.figure(figsize=(18, 6))

plt.subplot(1, 3, 1)
sns.scatterplot(x='average_time_alive', y='eliminations', hue='role', data=owl2020_data, palette=custom_palette)
plt.title('Average Time Alive vs. Eliminations')
plt.xlabel('Average Time Alive (sec)')
plt.ylabel('Eliminations')

plt.subplot(1, 3, 2)
sns.scatterplot(x='objective_time', y='eliminations', hue='role', data=owl2020_data, palette=custom_palette)
plt.title('Objective Time vs. Eliminations')
plt.xlabel('Objective Time (sec)')
plt.ylabel('Eliminations')

plt.subplot(1, 3, 3)
sns.scatterplot(x='average_time_alive', y='objective_time', hue='role', data=owl2020_data, palette=custom_palette)
plt.title('Average Time Alive vs. Objective Time')
plt.xlabel('Average Time Alive (sec)')
plt.ylabel('Objective Time (sec)')

plt.tight_layout()
plt.show()
```

## Summary

Overall this analysis has given us a good understanding of which players and heroes performed the best throughout the 2020 Overwatch League Season. If this was a game played by robots we would now be able to accurately predict which team was going to win every time, and which heroes should be picked. Alas, there are many things that cannot be evaluated by the statistics tracked in game. The decision making skills of the in-game leaders, the individual decisions that all 12 players are making in the heat of the moment, as well as the abilities that cannot be well measured like Lucio's speed boost.